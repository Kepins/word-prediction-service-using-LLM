from fastapi import APIRouter
from pydantic import BaseModel
from ..celery_app import inference

router = APIRouter(
    prefix='',
    responses={404: {'description': 'Not found'}},
)


class ResponseModel(BaseModel):
    """Response Model"""

    response: str


@router.put(
    '/',
    summary='Returns next token from LLM',
    description='Returns a next token generated from prompt.',
    response_model=ResponseModel,
)
def generate_next_token(prompt: str):
    """Returns the next token generated by LLaMA based on the prompt.

    - **prompt**: The prompt text to base the next token generation on.

    Example response:
    - **response**: The next token generated from the prompt.
    """
    task = inference.apply_async(kwargs={'prompt': prompt})
    return {'response': task.get()}
